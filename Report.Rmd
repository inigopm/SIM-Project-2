---
title: "Report"
author: "Inigo Pikabea and Max Tico"
date: "2023-11-27"
output: html_document
---

- TODOS:  Data validation is mixed of ‘common sense and sector knowledge’: Does the data make
sense? Does the data follow the appropriate rules for its field? Does it prove or disprove the
working theory, or bring any insight to light? Can you find trends in the data to help you form
a new theory? If not, is that because of a data quality issue?

```{r setup, include=FALSE}
# Clear plots
if(!is.null(dev.list())) dev.off()

# Clean workspace
rm(list=ls())

library(tidyverse);library(EnvStats);library(ggplot2); library(ggpubr); library(visdat)
library(FactoMineR);library(DataExplorer);library(mice); library(lmtest);library(gridExtra); library(chemometrics); library(car);library(regclass);library(missMDA);library(effects)


#setwd("C:/Users/usuario/Desktop/SIM/SIM-project-2")
knitr::opts_chunk$set(warnign=FALSE, message=FALSE)
```

```{r, read_data}
df <- read.csv("Data/WA_Fn-UseC_-Telco-Customer-Churn.xls")
```

GitHub was used as Version Control System for this project.

The contribution of each member is visible through the following repository: https://github.com/inigopm/SIM-Project-2.git

And the task distribution: https://github.com/inigopm/Projects

# Data preparation

As a first step, we imported the training data through the 'read_csv' function. 

Then we performed data preparation over the data. It consisted of 4 different steps: Univariate Descriptive Analysis, Data Quality report, Imputation and Profiling.

## Univariate Descriptive Analysis

Before performing the descriptive analysis, some variables had to be changed in order to better understand them and also to follow the same characteristics


```{r}
str(df)
summary(df)
```

Some numeric variables variables, corresponding to qualitative concepts, need to be converted to factors:
```{r}
columns_to_factor <- c("gender", "SeniorCitizen", "Partner", "Dependents", 
                        "PhoneService", "MultipleLines", "InternetService", 
                        "OnlineSecurity", "OnlineBackup", "DeviceProtection", 
                        "TechSupport", "StreamingTV", "StreamingMovies", "Contract", 
                        "PaperlessBilling", "PaymentMethod","Churn")

# Loop through each column and convert to factor
for (col in columns_to_factor) {
  df[[col]] <- factor(df[[col]])
}
```

For numeric variables corresponding to real quantitative concepts, we will keep them as numeric but we will create additional factors as a discretization of each one. For this purpose, we created a factor for each numeric variable, consisting of 4 different bins (values).

```{r}
# Monthly charges
# Define the breaks for discretization (bins)
breaks <- seq(0, 120, by = 30)  

# Create factor variable using cut()
df$factor_monthlycharges <- cut(df$MonthlyCharges, breaks = breaks, labels = c("Very_low", "Low", "Medium", "High"), include.lowest = TRUE)

# Total charges
# Define the breaks for discretization (bins)
breaks <- seq(18.8, 8684.8, by = 2000)  

# Create factor variable using cut()
df$factor_totalcharges <- cut(df$TotalCharges, breaks = breaks, labels = c("Very_low", "Low", "Medium", "High"), include.lowest = TRUE, na.rm = TRUE)
```

After this, we can now perform an Exploratory Data Analysis for each variable

*variable 1: Gender*

Gender is a binary variable composed of two values: Female & Male. We used a barplot to see the numbers of each binary value. We observed 3488 individuals corresponding to Female and 3555 individuals corresponding to Male. 
```{r}
summary(df$gender)

ggplot(data=df,aes(gender,fill=gender))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```
*variable 2: SeniorCitizen*

SeniorCitizen is a binary variable composed of two main values: 0 and 1. 0 represents that the customer is not a senior citizen and 1 yes. To visualize the distribution of values in this feature, we used a barplot. Here we observed a more unequal distribution of individuals across these two values: 5901 being not a senior citizen and 1142 being a senior citizen.
```{r}
summary(df$SeniorCitizen)

ggplot(data=df,aes(SeniorCitizen,fill=SeniorCitizen))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```
*variable 3: Partner*

Partner is a binary variable with two values: No and Yes (Yes having a partner and No not). We choose a barplot to better understand the distribution of our data across this feature. We did observe a balanced distribution, observing 3641 customer without partner and 3402 with partner.
```{r}
summary(df$Partner)

ggplot(data=df,aes(Partner,fill=Partner))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```

*variable 4: Dependents*

Dependents is a binary variable consisting of two main values: Yes (Customer has dependent) and No (Customer has not dependent). Again, we used a bar plot to visualize this variable. We observed 4933 individuals without dependent and 2110 individuals with dependent.
```{r}
summary(df$Dependents)

ggplot(data=df,aes(Dependents,fill=Dependents))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```
*variable 5: tenure*

Tenure is a numeric variable. This numeric variable has not NA or missing values. To visualize the distribution of this variable, we used a histogram and a boxplot. We observed that most individuals were comprised between 0 and 5. In the boxplot, we did not observe any outlier in this variable.
```{r}
summary(df$tenure)

hist(df$tenure)

length(Boxplot(df$tenure))

```
*variable 6: PhoneService*

PhoneService is a binary variable consisting of Yes (Customer with PhoneService) and No (Customer without PhoneService). In the graphic below, we observed an unbalanced distribution of values, observing 682 individuals without Phone service and 6361 individuals with phone service.
```{r}
summary(df$PhoneService)

ggplot(data=df,aes(PhoneService,fill=PhoneService))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```
*variable 7: MultipleLines*

MultipleLines is a factor variable which consists of three values: If customer has Phone Service, how many of them has multiple lines (Yes) or not (No). The third value represents those individual without Phone service. We observed 3390 customers without multiple lines, 2971 with multiple lines and again, consistent with the values from the previous variable (PhoneService), 682 individuals without phone service.
```{r}
summary(df$MultipleLines)

ggplot(data=df,aes(MultipleLines,fill=MultipleLines))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```
*variable 8: InternetService*

InternetService is a factor variable consisting of three values: DSL, Fiber Optic and No. In the barplot below, we observed 2421 individuals having DSL, 3096 having Fiber Optic and 1526 without internet service. 
```{r}
summary(df$InternetService)

ggplot(data=df,aes(InternetService,fill=InternetService))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```

*variable 9: OnlineSecurity*

OnlineSecurity is a factor variable which has three values: From those individuals with internet service, how many of them have online security (Yes) or not (No). The third value corresponds to those customers without internet service. We observed 2019 customers with online security, 3498 without online security, and 1526 individuals without internet service (consistent with previous analysis).
```{r}
summary(df$OnlineSecurity)

ggplot(data=df,aes(OnlineSecurity,fill=OnlineSecurity))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```

*variable 10: OnlineBackup*

OnlineBackup is a factor variable which has three values: From those individuals with internet service, how many of them have online backup (Yes) or not (No). The third value corresponds to those customers without internet service. We observed 2429 customers with online backup, 3088 without online backup, and 1526 individuals without internet service (consistent with previous analysis).
```{r}
summary(df$OnlineBackup)

ggplot(data=df,aes(OnlineBackup,fill=OnlineBackup))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```

*variable 11: DeviceProtection*

DeviceProtection is a factor variable which has three values: From those individuals with internet service, how many of them have device protection (Yes) or not (No). The third value corresponds to those customers without internet service. We observed 2422 customers with device protection, 3095 without device protection, and 1526 individuals without internet service (consistent with previous analysis).
```{r}
summary(df$DeviceProtection)

ggplot(data=df,aes(DeviceProtection,fill=DeviceProtection))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```

*variable 12: TechSupport*

TechSupport is a factor variable which has three values: From those individuals with internet service, how many of them have tech support (Yes) or not (No). The third value corresponds to those customers without internet service. We observed 2044 customers with tech support, 3473 without tech support, and 1526 individuals without internet service (consistent with previous analysis).
```{r}
summary(df$TechSupport)

ggplot(data=df,aes(TechSupport,fill=TechSupport))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```

*variable 13: StreamingTV*

StreamingTV is a factor variable which has three values: From those individuals with internet service, how many of them have StreamingTV (Yes) or not (No). The third value corresponds to those customers without internet service. We observed 2707 customers with StreamingTV, 2810 without StreamingTV, and 1526 individuals without internet service (consistent with previous analysis).
```{r}
summary(df$StreamingTV)

ggplot(data=df,aes(StreamingTV,fill=StreamingTV))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```

*variable 14: StreamingMovies*

StreamingMovies is a factor variable which has three values: From those individuals with internet service, how many of them have StreamingMovies (Yes) or not (No). The third value corresponds to those customers without internet service. We observed 2732 customers with StreamingMovies, 2785 without StreamingMovies, and 1526 individuals without internet service (consistent with previous analysis).
```{r}
summary(df$StreamingMovies)

ggplot(data=df,aes(StreamingMovies,fill=StreamingMovies))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```

*variable 15: Contract*

Contract is a factor variable consisting of three values: Month-to-month, One year and Two year. In the plot below, we observed 3875 individuals having a month-to-month contract, 1473 customers with one year contract and the remaining 1695 having a two year contract.
```{r}
summary(df$Contract)

ggplot(data=df,aes(Contract,fill=Contract))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```

*variable 16: PaperlessBilling*

PaperlessBilling is a binary variable. Yes (4171 individuals) represents that the customer has paper billing and No (2872 individuals) the opposite. 
```{r}
summary(df$PaperlessBilling)

ggplot(data=df,aes(PaperlessBilling,fill=PaperlessBilling))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```

*variable 17: PaymentMethod*

PaymentMethod is a factor variable consisting of four main values: Bank transfer (1544 customers), credit card (1522 customers), electronic check (2365 customers) and mailed check (1612 customers). 
```{r}
summary(df$PaymentMethod)

ggplot(data=df,aes(PaymentMethod,fill=PaymentMethod))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```

*variable 18: Churn*

Churn is a binary variable representing if customers churned (Yes) or not (No). We found that 1869 individuals churned and 5174 not.   
```{r}
summary(df$Churn)

ggplot(data=df,aes(Churn,fill=Churn))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```

*variable 19: Monthly Charges (factor)*

Monthly charges was originally a numerical variable converted into a categorical variable where each value corresponds to a numeric interval. The values of this feature are_ Very_low, low, medium and high. 
```{r}
summary(df$factor_monthlycharges)

ggplot(data=df,aes(factor_monthlycharges,fill=factor_monthlycharges))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```

*variable 20: Total Charges (factor)*

Total charges was originally a numerical variable converted into a categorical variable where each value corresponds to a numeric interval. The values of this feature are_ Very_low, low, medium and high. Here we observed some NA's (85). 
```{r}
summary(df$factor_totalcharges)

ggplot(data=df,aes(factor_totalcharges,fill=factor_totalcharges))+
  geom_bar()+
  stat_count(geom = "text", colour = "black", size = 3.5,
              aes(label = after_stat(count)),position=position_stack(vjust=0.5))
```

## Univariate and Multivariate analysis.

After taking the only 3 numeric values, the analysis showed that there are no univariate outliers. The lack of univariate outliers in the data suggests that the values within each of these variables fall within a reasonable range, without extreme values that could skew the analysis.

-- FALTA COMENTAR MULTIVARIATE ANALYSIS (NO SE COMO INTERPRETAR LA GRAFICA)

```{r}

num_outliers <- c("tenure", "MonthlyCharges", "TotalCharges")
for(i in 1:length(num_outliers)) {
  columna <- num_outliers[i]
  
  # Calculate the thresholds
  q1 <- quantile(df[columna],0.25, na.rm = TRUE) 
  q3 <- quantile(df[columna],0.75, na.rm = TRUE) 
  iqr <- q3 - q1
  mild_l <- q1 - iqr*1.5
  mild_h <- q3 + iqr*1.5
  high_l <- q1 - iqr*3
  high_h <- q3 + iqr*3
  
  # Create the plot
  p <- ggplot(df, aes(x=!!sym(columna))) +
    geom_histogram(color="black", fill="white", bins=30) +
    geom_vline(aes(xintercept=mild_l), color="blue", linetype="dashed") +
    geom_vline(aes(xintercept=mild_h), color="blue", linetype="dashed") +
    geom_vline(aes(xintercept=high_l), color="red", linetype="dashed") +
    geom_vline(aes(xintercept=high_h), color="red", linetype="dashed") +
    labs(x = columna, y="Frequency", title = paste("Histogram of", columna))
  # Add the plot to the list
  print(p)
}

res.out = Moutlier(df[, num_outliers], quantile = 0.9995, col="green")

outlier_index <- which((res.out$md > res.out$cutoff)&(res.out$rd > res.out$cutoff))
length(outlier_index)

par(mfrow=c(1,1))
plot( res.out$md, res.out$rd )
abline(h=res.out$cutoff, col="red")
abline(v=res.out$cutoff, col="red")

```

## Data Quality Report

Afterwards, for each variable we counted the number of missing values and ranked them according to the sum of missing values. In total, we found 95 missing values, corresponding to variables
TotalCharges and factor_totalcharges. We performed a boxplot for every numerical feature in order to identify outliers but no outliers were identified.
```{r}
missing_counts <- colSums(is.na(df));missing_counts

total_missings <- sum(is.na(df));total_missings

# Outlier detection
length(Boxplot(df$tenure, id = list(n = Inf)))
length(Boxplot(df$MonthlyCharges, id = list(n = Inf)))
length(Boxplot(df$TotalCharges, id = list(n = Inf)))

```

We also counted the number of missings per individuals and number of outliers (including multivariant outliers). There are some individuals which have up to two missings. 
```{r}
missing_per_individual <- rowSums(is.na(df));missing_per_individual
```

Falta create variable ???

## Imputation

As we observed before, there are some variables of our dataset with missing values (TotalCharges & factor_totalcharges). In order to solve this, we imputed those values. As one of this variables is numeric and the other one is categorical, we had to follow different approaches. For the numeric variable, we used imputePCA() function from missMDA library. For the categoric variable we used imputeMCA() function from missMDA library too, which is helpful for imputation of missing values in categorical features.
```{r}
# Imputation of numeric variable TotalCharges
res.pca <- imputePCA(df[, c(6,19:20)])
df$TotalCharges <- res.pca$completeObs[, 3]

# Imputation of categorical variable factor_totalcharges
res.mca <- imputeMCA(df[, c(2:5,7:18,21:23)])
df$factor_totalcharges <- res.mca$completeObs[, 19]
```

## Profiling

Catdes() is an R function from FactoMineR which is used to describe one factor by categorical variables and/or by qualitative variables. First we analyzed the categorical variables which characterized our binary target variable. In the test.chi2 we can observe that all variables are significant. From those, the ones that exhibited the lowest p.value were Contract, OnlineSecurity, TechSupport, InternetService, PaymentMethod, OnlineBackup & DeviceProtection. 
We lately focused on the description of each category of our binary variable by the categories of all categorical variables in our dataset. We observed that Two-year contract factor had the lowest p.value among all factors in No category (Churn), meaning that it is a very important factor to describe the No category. The following categories, where corresponding to no Internet Service in different variables. This can be explained as it is the same value repeated in many columns. For the Yes category, we found that Month-to-month factor from Contract variable had lowest p.value, being the category describing 'Yes' the most. For the following categories we observed the same pattern as in 'No' category.

```{r}
catdes.res <- catdes(df,21)
# Assessing which categorical variables characterized the most our target
catdes.res$test.chi2
# Description of each category by all categorical variables
catdes.res$category
```

# Separation between Train and Test datasets

We will perform separation of the data into train and test.
```{r}
set.seed(123)
# Create an index to randomly split the data
index <- sample(1:nrow(df), nrow(df)*0.8)  # 80% for training, 20% for testing
# Create the training set
train_data <- df[index, ]
# Create the testing set
test_data <- df[-index, ]
```

# Modeling using numeric variables.

Five logistic regression models were developed to predict customer churn using different combinations and transformations of the numeric variables tenure, MonthlyCharges, and TotalCharges.

Model 1 incorporated all three variables (tenure, MonthlyCharges, TotalCharges). However, high multicollinearity was detected between tenure and TotalCharges, leading to their exclusion due to redundancy. This model yielded an AIC of 5205.915.

Model 2 simplified the approach by using only tenure and MonthlyCharges, resulting in significantly reduced multicollinearity (VIF ~ 1.29 for both variables).

Model 3 explored the effect of transforming MonthlyCharges into a logarithmic scale, hypothesizing a non-linear relationship with churn. This model, however, showed a slight increase in the AIC, suggesting it may not improve the prediction over the simpler Model 2.

Model 4 introduced an interaction term between tenure and MonthlyCharges.

Model 5 took a more complex approach, using polynomial transformations for both tenure and MonthlyCharges. This model achieved the lowest AIC, indicating a better fit. However, the complexity of this model, with higher-order polynomials, might lead to overfitting and interpretability challenges, despite its apparent predictive power.

Model 6 was a combination of model 2 and model 5, but trying to simplify to the maximum our model. We introduced no interaction between our variables, but we added a polynomial of degree two to Tenure. This model obtained an AIC higher than model 5 but lower than all the other models.

Having computed all these models, we decided to take model 6 as our final numerical model. In comparison to model 5, it has a relatively high AIC (>100 of difference), but is simpler. Model 5 consists of the two variables with very high polynomials (7 and 11). 
```{r}
mod1 <- glm(Churn ~ tenure + MonthlyCharges + TotalCharges, family="binomial", data=train_data)
mod1
vif(mod1) # Correlacion muy alta entre Total y tenure. Quitamos Total por ser ombinacion lineal de tenure.
AIC(mod1)

mod2 <- glm(Churn ~ tenure + MonthlyCharges, family="binomial", data=train_data)
mod2
vif(mod2)
AIC(mod2)

# Using transformations
mod3 <- glm(Churn ~ tenure + log(MonthlyCharges), family="binomial", data=train_data)
mod3
vif(mod3)
AIC(mod3)

mod4 <- glm(Churn ~ tenure * MonthlyCharges, family="binomial", data=train_data)
mod4
vif(mod4)
AIC(mod4)


mod5 <- glm(Churn ~ poly(tenure, 7) + poly(MonthlyCharges, 11), family="binomial", data=train_data)
mod5
vif(mod5)
AIC(mod5)

mod6 <- glm(Churn ~ poly(tenure, 2) + MonthlyCharges, family="binomial", data=train_data)
mod6
vif(mod6)
AIC(mod6)
```

# Residual Analysis

Once our numerical model was chosen, we wanted to validate it. To validate the quality of our model we search for the no-linearity of the variance between the errors of the predictor variables and the class. 

Residual plots show pearson residuals in relation with predictor variables and the linear predictor. Within these plots we want to search the absence of clear patterns, which could indicate no-linearities or heteroscedasticity (inconstant variability of the residuals).

In the first two plots (Linear part of poly(tenure, 2) , MonthlyCharges) we do not observe clear/systematic patterns between variables and residuals, suggesting a constant variability of the errors. We do not observe clear signals of no-linearity or heteroscedasticity.

The Linear Predictor plot shows the residuals vs the adjusted values (linear predictor). We expected to observe distributed across the horizontal line in zero. In our plot we observe a tendency of the residuals to deviate from zero, indicating that the model is not capturing well the variability of the residuals.

The Marginal Model Plots show the relationship between each predictor and the response, where the red dotted line represents the predictions of the model and the blue line represents the real data. 

Although in poly(tenure,2) the model deviates a little bit from the real data, in general terms we can observe in both plots that the model captures correctly the tendency of the data.

The Effect plots show the relationship between the predictors and the Churn probability. The blue shadow indicates the confidence interval. 

In the Tenure effect plot we observe a non-linear relationship, decreasing the probability of churn as Tenure increases. The MonthlyCharges plot indicates that as MonthlyCharges increase, the probability of Churn also increases. This was expected as the customers tend to leave the company of their monthly charges increase / are higher.

Influence Plots visualize the influence of each observation in the model, being the size of the points proportional to Cook's distance (influence measure).

Most of the observations have low leverage values, indicating that there are not high influent data. There are 6 individuals (6119, 269, 4587, 4150, 6425 and 431) with a higher Cook's distance, being the most influent data in the model.

```{r}

par("mar")
par(mar=c(1,1,1,1))
residualPlots(mod6)
marginalModelPlots(mod6)
plot(allEffects(mod6))
influencePlot(mod6)

```

# Adding Factors to our model

After having created and validated our model with numerical variables, we decided to incorporate all the factor variables of the dataset into our model. As it is a very big model, we wanted to select the most significant variables to Churn. We used two different approaches: Anova and Step. With the results from both approaches, we decided to create two different models (mod8 & mod9). Then we performed a comparison between both of them to see which one of the two had the best AIC. We observed that mod8, corresponding to the model with Anova results, had an AIC of 4988, even higher than the model with all factors (4753). On the other hand mod9, corresponding to step results, had a better AIC, even compared to the original model (4746 vs 4753). 
To gain validation to mod9, we compared mod8 and mod9 with anova (different from Anova). The anova method shows a p-value when comparing models, which tells us about the improvement of one model compared to the other. In our case, we observed a very significant p-value from mod9, meaning that mod9 significantly improves mod8, so we decided to keep it as our final factor model.

```{r}

mod7 <- glm(Churn ~ poly(tenure, 2) + MonthlyCharges + gender + SeniorCitizen + Partner
            + Dependents + PhoneService + MultipleLines + InternetService + OnlineSecurity
            + OnlineBackup + DeviceProtection + TechSupport + StreamingTV + StreamingMovies
            + Contract + PaperlessBilling + PaymentMethod, family="binomial", data=train_data)
mod7

# Removing non-significant variables
Anova(mod7, test="LR")
step(mod7)

mod8 <- glm(Churn ~ poly(tenure, 2) + SeniorCitizen + MultipleLines
            + Contract + PaperlessBilling + PaymentMethod, family="binomial", data=train_data)
AIC(mod8)
mod9 <- glm(formula = Churn ~ poly(tenure, 2) + MonthlyCharges + SeniorCitizen + 
    MultipleLines + InternetService + OnlineSecurity + TechSupport + 
    StreamingTV + StreamingMovies + Contract + PaperlessBilling + 
    PaymentMethod, family = "binomial", data = train_data)
AIC(mod9)

anova(mod8, mod9, test="Chisq")

```

# Residual Analysis: Factors

We next validated our model with the same approach we used before. For poly(tenure, 2) & MonthlyCharges we do not observe systematic patterns neither heteroscedasticity. This indicates that the transformations and the linear relationship for these variables are correct.

For factor variables we observe that the vast majority of observations are distributed around 0, indicating a uniform performance of the model across the different groups of these variables. Nonetheless, there are some observations which differ from 0, which could suggest they're influent data.

In the Marginal Plots we see that the model follows the tendency of the real data, suggesting that the model adjusts correctly to the variability in these predictors.

In the influence plot, the majority of observations have a low influence in the model. However, there are some individuals containing a relatively high Cook's distance, suggesting that those observations are influent data. These points need a more detailed analysis in order to determine if they represent atypical values.

In comparison with the previous residual analysis, we did observe one individual which keeps being influent in our model, which is 269.

```{r}

par("mar")
par(mar=c(1,1,1,1))
residualPlots(mod9)
marginalModelPlots(mod9)
# plot(allEffects(mod9)) -- da error
influencePlot(mod9)

```

# Modeling with interactions

In order to build our model with interactions, first we decided to perform an Anova to observe which are the most significant variables in our model and transform those. Here we observed that almost all are significant, but the ones with lower p-value are tenure, InternetService, Contract, PaperlessBilling & PaymentMethod.

As Contract and Tenure were the most significant variables, we decided to create a model with interactions between them. We observed that with this model the AIC value decreased from 4746 (mod9) to 4729 (mod10). To see if mod10 was significantly different from mod9, we performed an anova. Here we obtained a p-value near 0 (6.415e-05) meaning that mod10 was significantly different from mod9.

As creating interactions between the most significant variables exhibited a decrease in the AIC value and significance, we decided to create PaperlessBilling and PaymentMethod (maintaining the interaction before). It showed an AIC value lower than mod9 (4732) but higher than mod10.

Finally we decided to create a model maintaining the first interaction with Tenure and Contract, but creating interactions between the less significant variables, as the approach we performed before didn't performed correctly. In mod12 we introduced an interaction between MonthlyCharges and SeniorCitizen and another one between OnlineSecurity and Techsupport. We observed a decrease in the AIC value (4724) compared to mod9 and mod10. To see whether this model was significantly different from mod10 we used again anova. Here we observed a significance (p-value of 0.01), meaning that this model is different from the one created before.

```{r}
Anova(mod9, test="LR")

# Interaction between tenure & Contract
mod10 <- glm(formula = Churn ~ poly(tenure, 2) * Contract + MonthlyCharges + SeniorCitizen + 
    MultipleLines + InternetService + OnlineSecurity + TechSupport + 
    StreamingTV + StreamingMovies + PaperlessBilling + 
    PaymentMethod, family = "binomial", data = train_data)
AIC(mod10)
anova(mod9,mod10,test = "Chisq")

# Interaction with PaperlessBilling and PaymentMethod
mod11 <- glm(formula = Churn ~ poly(tenure, 2) * Contract + MonthlyCharges + SeniorCitizen + 
    MultipleLines + InternetService + OnlineSecurity + TechSupport + 
    StreamingTV + StreamingMovies + PaperlessBilling * 
    PaymentMethod, family = "binomial", data = train_data)
AIC(mod11)

anova(mod10,mod11,test = "Chisq")

# Interaction between less significant variables
mod12 <- glm(formula = Churn ~ poly(tenure, 2) * Contract + MonthlyCharges * SeniorCitizen + 
    MultipleLines + InternetService + OnlineSecurity * TechSupport + 
    StreamingTV + StreamingMovies + PaperlessBilling + 
    PaymentMethod, family = "binomial", data = train_data)
AIC(mod12)

anova(mod10,mod12,test = "Chisq")
anova(mod9,mod12,test = "Chisq")

```

# Final Residual Analysis

- 

```{r}
par("mar")
par(mar=c(1,1,1,1))
residualPlots(mod9)
marginalModelPlots(mod9)
# plot(allEffects(mod9)) -- da error
influencePlot(mod9)
```

# Goodness of fit and Model Interpretation

- USAR EL TEST SET
- VER CUANTO HA OVERFITTEAO Y CUANTO ACIERTA EN EL TEST EN COMPARACION CON EL TRAIN. SACAR EL ACCURACY (CONFUSION MATRIX, ROC CURVE, ETC)